{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the goods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "string.punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jonnyoh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jonnyoh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jonnyoh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jonnyoh/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'omfh.csv'\n",
    "filename = 'combined_courses3.csv'\n",
    "data_folder_path = os.path.join(os.getcwd(), '..', 'raw_data')\n",
    "file_path = os.path.join(data_folder_path, filename)\n",
    "\n",
    "df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_csv(df, filename):\n",
    "    \"\"\" Saves the given DataFrame to a CSV file in the current directory\"\"\"\n",
    "    file_path = os.path.join(os.getcwd(), filename)\n",
    "\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"DataFrame saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to /home/jonnyoh/code/cipobt/breathworks/notebooks/combined_courses3.csv\n"
     ]
    }
   ],
   "source": [
    "save_df_to_csv(df,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "textual = ['PersonalHistory', 'Motivation', 'ReferralSource', 'Daily20MPractice']\n",
    "catagorical = ['CourseType', 'Gender', 'Ethnicity', 'Location']\n",
    "datetime = ['CourseDate', 'EnrollmentDate', 'DoB']\n",
    "non_textual = catagorical + datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Text cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        cleaned_data = X.applymap(self.clean_text)\n",
    "        return cleaned_data\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = str(text)\n",
    "        for punctuation in string.punctuation:\n",
    "            text = text.replace(punctuation, ' ')  # Remove Punctuation\n",
    "        lowercased = text.lower()  # Lower Case\n",
    "        tokenized = word_tokenize(lowercased)  # Tokenize\n",
    "        words_only = [word for word in tokenized if word.isalpha()]  # Remove numbers\n",
    "\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stop_words.update(['yes','none','nan'])\n",
    "\n",
    "        without_stopwords = [word for word in words_only if not word in stop_words]  # Remove Stop Words\n",
    "        lemma = WordNetLemmatizer()  # Initiate Lemmatizer\n",
    "        lemmatized = [lemma.lemmatize(word) for word in without_stopwords]  # Lemmatize\n",
    "        cleaned = ' '.join(lemmatized)  # Join back to a string\n",
    "        return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TextCleaner(), textual)\n",
    "    ],\n",
    "    remainder='passthrough'  # Non-specified columns will be passed through unchanged\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = preprocessor.fit_transform(df)\n",
    "transformed_columns = textual + [col for col in df.columns if col not in textual]\n",
    "df_cleaned = pd.DataFrame(df_transformed, columns=transformed_columns)\n",
    "df_dropped = df_cleaned.drop(columns=non_textual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model, vectorizer, num_topics=3, num_words=10):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names_out()[i], topic[i])\n",
    "               for i in topic.argsort()[:-num_words - 1:-1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________Topics for PersonalHistory:_____________________\n",
      "Topic 0:\n",
      "[('pain', 2098.4634167563845), ('condition', 2082.697315811877), ('chronic', 2031.201665968884), ('currently', 1825.1894254610982), ('identify', 1731.1338242147767), ('syndrome', 29.985498164230346), ('fibromyalgia', 28.922260090014028), ('fatigue', 25.348274817955772), ('debilitating', 17.876284892257047), ('migraine', 17.231204837177213)]\n",
      "Topic 1:\n",
      "[('depression', 952.5171401161873), ('anxiety', 810.6642378003028), ('pain', 480.53658324360447), ('year', 448.3784845639723), ('health', 426.04646326820676), ('experienced', 379.44909356532145), ('experience', 371.367224257769), ('month', 352.45722893103544), ('mental', 331.1912105360553), ('debilitating', 324.1237151077334)]\n",
      "____________________Topics for Motivation:_____________________\n",
      "Topic 0:\n",
      "[('mindfulness', 1832.500541750095), ('course', 1590.46564732921), ('teacher', 861.996040152912), ('practice', 762.0346737509859), ('training', 714.3433375027163), ('like', 696.9536178329512), ('breathworks', 598.2572464539043), ('year', 512.7122187913025), ('meditation', 509.58500902356457), ('health', 369.7973691096899)]\n",
      "Topic 1:\n",
      "[('stress', 709.8675142852433), ('pain', 698.8513012105844), ('help', 623.8504608786329), ('life', 543.515851164693), ('anxiety', 445.0802166150376), ('year', 410.28778120868213), ('work', 405.2953285631066), ('learn', 386.10532998441965), ('mindfulness', 367.4994582498939), ('like', 349.04638216703455)]\n",
      "____________________Topics for ReferralSource:_____________________\n",
      "Topic 0:\n",
      "[('website', 708.4837120552172), ('search', 253.492560500864), ('internet', 250.49254243020255), ('member', 144.87544520647145), ('mindfulness', 49.49465405745894), ('book', 41.232109585295305), ('centre', 39.49490836451951), ('buddhist', 38.49494683852141), ('course', 28.467008548048426), ('vidyamala', 25.570620893866742)]\n",
      "Topic 1:\n",
      "[('friend', 691.4676408664855), ('family', 690.4688200667232), ('colleague', 593.4906995347133), ('hospital', 107.48589350255828), ('doctor', 106.48580043347609), ('work', 103.47410212013068), ('event', 53.47058654300267), ('magazine', 28.471472301947426), ('group', 25.486513313895294), ('support', 24.48617595762544)]\n",
      "____________________Topics for Daily20MPractice:_____________________\n",
      "Topic 0:\n",
      "[('practice', 1983.9728907811905), ('day', 1972.398027346767), ('mindfulness', 1952.3430317259795), ('minute', 1934.8517545647815), ('able', 1914.1738425842427), ('technique', 1883.4562236828772), ('exercise', 1882.4552664122903), ('course', 1042.9017160235974), ('duration', 1010.4525820060032), ('ye', 1.4903797542588229)]\n",
      "Topic 1:\n",
      "[('group', 124.49494428657133), ('meditation', 88.47153831050993), ('time', 76.4854452694377), ('daily', 76.47813024665176), ('work', 74.48976809248462), ('practice', 56.02710921880507), ('try', 50.480160517017374), ('currently', 45.48176595392398), ('year', 45.48088721072287), ('course', 45.0982839763972)]\n"
     ]
    }
   ],
   "source": [
    "for column in textual:\n",
    "    data_vectorized = vectorizer.fit_transform(df_dropped[column].values.astype('U'))\n",
    "\n",
    "    # Initialize and fit the LDA model\n",
    "    lda_model = LatentDirichletAllocation(n_components=2)\n",
    "    lda_vectors = lda_model.fit_transform(data_vectorized)\n",
    "\n",
    "    # Print the topics found by the LDA model\n",
    "    print(f\"____________________Topics for {column}:_____________________\")\n",
    "    print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________Combined Topics:_____________________\n",
      "Topic 0:\n",
      "[('level', 30.444018749889697), ('stress', 28.459953873615927), ('help', 22.510444166322326), ('time', 18.20889720755411), ('medication', 16.05968327517491), ('diagnosed', 14.438841008658946), ('group', 13.235709713041528), ('suffered', 12.730361680436662), ('need', 12.671311511625706), ('thing', 12.264988080969657)]\n",
      "Topic 1:\n",
      "[('pain', 377.25465239943145), ('month', 145.83705867721366), ('experienced', 140.37163625163092), ('persistent', 136.62741357732955), ('lasted', 128.82662265184243), ('year', 127.35155396402565), ('help', 72.50116053691669), ('feel', 71.94432611292183), ('time', 71.52398219827296), ('like', 71.3543917102478)]\n",
      "Topic 2:\n",
      "[('mindfulness', 2012.876149947978), ('course', 1531.3735743381533), ('practice', 1210.6285605525848), ('teacher', 704.2978471957664), ('currently', 673.1955012536064), ('day', 644.9272699663189), ('pain', 635.5770667326938), ('able', 614.2426864233403), ('condition', 604.4490192396482), ('training', 602.4543081582286)]\n",
      "Topic 3:\n",
      "[('pain', 788.4622059376961), ('chronic', 558.438097351181), ('condition', 480.56476692012615), ('currently', 396.4332280949136), ('identify', 365.70150223007084), ('life', 133.5503227432286), ('health', 130.9113898732242), ('help', 122.88784289900755), ('learn', 120.28222025924173), ('better', 106.97083425185404)]\n",
      "Topic 4:\n",
      "[('pain', 596.9605954519874), ('chronic', 482.84724734882843), ('condition', 434.58489109486624), ('currently', 387.6833052564512), ('identify', 381.6173993136294), ('teacher', 178.0799092886251), ('friend', 174.3515633176899), ('family', 172.76110603700158), ('course', 142.18118440666515), ('colleague', 133.09623623657242)]\n",
      "Topic 5:\n",
      "[('mindfulness', 1230.5838267394167), ('practice', 940.7376188541855), ('day', 818.3980901395499), ('able', 774.0033498421171), ('technique', 742.5208875558682), ('exercise', 691.1906667356133), ('minute', 676.1603610760832), ('course', 647.5975565140969), ('anxiety', 621.4493080762813), ('stress', 573.2414719004994)]\n",
      "Topic 6:\n",
      "[('pain', 1181.4036968839903), ('mindfulness', 1005.1892068573808), ('condition', 840.5865272148199), ('practice', 804.6940448804256), ('able', 793.6387901597454), ('day', 787.2523592437329), ('chronic', 787.2426830024384), ('technique', 777.5267315447607), ('exercise', 729.043157725601), ('minute', 728.3703762353199)]\n"
     ]
    }
   ],
   "source": [
    "combined_text = df_dropped[textual].apply(lambda x: ' '.join(x.dropna().values.astype('U')), axis=1)\n",
    "data_vectorized = vectorizer.fit_transform(combined_text)\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=7, random_state=0)\n",
    "lda_vectors = lda_model.fit_transform(data_vectorized)\n",
    "\n",
    "# Modified print_topics function\n",
    "def print_topics(model, vectorizer, num_words=10):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {idx}:\")\n",
    "        print([(vectorizer.get_feature_names_out()[i], topic[i])\n",
    "               for i in topic.argsort()[:-num_words - 1:-1]])\n",
    "\n",
    "# Step 4: Print the topics found by the LDA model across all combined textual data\n",
    "print(\"____________________Combined Topics:_____________________\")\n",
    "print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

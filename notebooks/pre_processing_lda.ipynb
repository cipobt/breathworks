{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**importing the goods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/jonnyoh/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (3.7)\n",
      "Requirement already satisfied: click in /home/jonnyoh/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/jonnyoh/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/jonnyoh/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from nltk) (2022.9.13)\n",
      "Requirement already satisfied: tqdm in /home/jonnyoh/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from nltk) (4.64.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "string.punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jonnyoh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jonnyoh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jonnyoh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jonnyoh/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting our dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'omfh.csv'\n",
    "data_folder_path = os.path.join(os.getcwd(), '..', 'raw_data')\n",
    "file_path = os.path.join(data_folder_path, filename)\n",
    "\n",
    "df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_csv(df, filename):\n",
    "    \"\"\" Saves the given DataFrame to a CSV file in the current directory\"\"\"\n",
    "    file_path = os.path.join(os.getcwd(), filename)\n",
    "\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"DataFrame saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to /home/jonnyoh/code/cipobt/breathworks/notebooks/omfh.csv\n"
     ]
    }
   ],
   "source": [
    "save_df_to_csv(df,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "textual = ['PersonalHistory', 'Motivation', 'ReferralSource', 'Daily20MPractice']\n",
    "catagorical = ['CourseType', 'Gender', 'Ethnicity', 'Location']\n",
    "datetime = ['CourseDate', 'EnrollmentDate', 'DoB']\n",
    "non_textual = catagorical + datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        cleaned_data = X.applymap(self.clean_text)\n",
    "        return cleaned_data\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = str(text)\n",
    "        for punctuation in string.punctuation:\n",
    "            text = text.replace(punctuation, ' ')  # Remove Punctuation\n",
    "        lowercased = text.lower()  # Lower Case\n",
    "        tokenized = word_tokenize(lowercased)  # Tokenize\n",
    "        words_only = [word for word in tokenized if word.isalpha()]  # Remove numbers\n",
    "\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stop_words.update(['yes','none'])\n",
    "\n",
    "        without_stopwords = [word for word in words_only if not word in stop_words]  # Remove Stop Words\n",
    "        lemma = WordNetLemmatizer()  # Initiate Lemmatizer\n",
    "        lemmatized = [lemma.lemmatize(word) for word in without_stopwords]  # Lemmatize\n",
    "        cleaned = ' '.join(lemmatized)  # Join back to a string\n",
    "        return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TextCleaner(), textual)\n",
    "    ],\n",
    "    remainder='passthrough'  # Non-specified columns will be passed through unchanged\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = preprocessor.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_columns = textual + [col for col in df.columns if col not in textual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonalHistory</th>\n",
       "      <th>Motivation</th>\n",
       "      <th>ReferralSource</th>\n",
       "      <th>Daily20MPractice</th>\n",
       "      <th>CourseDate</th>\n",
       "      <th>CourseType</th>\n",
       "      <th>EnrollmentDate</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>DoB</th>\n",
       "      <th>Location</th>\n",
       "      <th>Communications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>issue fatigue stress currently identify chroni...</td>\n",
       "      <td>occupational therapist working nh patient long...</td>\n",
       "      <td>website</td>\n",
       "      <td></td>\n",
       "      <td>2024-04-03</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>2024-02-22</td>\n",
       "      <td>Female</td>\n",
       "      <td>White (including White British, Irish, Gypsy o...</td>\n",
       "      <td>08/03/1967</td>\n",
       "      <td>Magdalen Square, Liverpool</td>\n",
       "      <td>Ongoing support communications sign up, I woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>migraine disc hernia neck undiagnosed knee pai...</td>\n",
       "      <td>joining course hope cn find useful technique h...</td>\n",
       "      <td>internet search</td>\n",
       "      <td></td>\n",
       "      <td>2024-06-02</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>2024-02-22</td>\n",
       "      <td>Female</td>\n",
       "      <td>White (including White British, Irish, Gypsy o...</td>\n",
       "      <td>29/11/1981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ongoing support communications sign up, I woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>auto immune issue experience frequent gastric ...</td>\n",
       "      <td>always high stress consistently advised someth...</td>\n",
       "      <td>internet search</td>\n",
       "      <td></td>\n",
       "      <td>2024-03-07</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>Female</td>\n",
       "      <td>White (including White British, Irish, Gypsy o...</td>\n",
       "      <td>07/03/1975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ongoing support communications sign up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fm long covid experienced persistent pain last...</td>\n",
       "      <td>looking forward joining course fm also long co...</td>\n",
       "      <td>work work colleague</td>\n",
       "      <td></td>\n",
       "      <td>2024-03-07</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>Female</td>\n",
       "      <td>White (including White British, Irish, Gypsy o...</td>\n",
       "      <td>09/06/1974</td>\n",
       "      <td>Merseyside</td>\n",
       "      <td>Ongoing support communications sign up, I woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>experienced persistent pain lasted least last ...</td>\n",
       "      <td>suffering chronic pain hope manage better</td>\n",
       "      <td>book</td>\n",
       "      <td></td>\n",
       "      <td>2024-03-07</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>Female</td>\n",
       "      <td>White (including White British, Irish, Gypsy o...</td>\n",
       "      <td>03/09/1966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>currently identify chronic pain condition</td>\n",
       "      <td>practicing mindfulness since mid also teaching...</td>\n",
       "      <td>website</td>\n",
       "      <td>nan</td>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>2014-12-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>currently identify chronic pain condition</td>\n",
       "      <td>taking course pre requisite breathworks course...</td>\n",
       "      <td>friend family colleague</td>\n",
       "      <td>nan</td>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>2014-12-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>currently identify chronic pain condition</td>\n",
       "      <td>would like attend breathworks training given c...</td>\n",
       "      <td>friend family colleague</td>\n",
       "      <td>nan</td>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>2014-12-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>currently identify chronic pain condition</td>\n",
       "      <td>meditating two year inconsistently using cd bo...</td>\n",
       "      <td>website</td>\n",
       "      <td>nan</td>\n",
       "      <td>2015-02-02</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>2014-11-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>currently identify chronic pain condition</td>\n",
       "      <td>work support worker community mental health te...</td>\n",
       "      <td>website</td>\n",
       "      <td>nan</td>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>2014-11-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1398 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        PersonalHistory  \\\n",
       "0     issue fatigue stress currently identify chroni...   \n",
       "1     migraine disc hernia neck undiagnosed knee pai...   \n",
       "2     auto immune issue experience frequent gastric ...   \n",
       "3     fm long covid experienced persistent pain last...   \n",
       "4     experienced persistent pain lasted least last ...   \n",
       "...                                                 ...   \n",
       "1393          currently identify chronic pain condition   \n",
       "1394          currently identify chronic pain condition   \n",
       "1395          currently identify chronic pain condition   \n",
       "1396          currently identify chronic pain condition   \n",
       "1397          currently identify chronic pain condition   \n",
       "\n",
       "                                             Motivation  \\\n",
       "0     occupational therapist working nh patient long...   \n",
       "1     joining course hope cn find useful technique h...   \n",
       "2     always high stress consistently advised someth...   \n",
       "3     looking forward joining course fm also long co...   \n",
       "4             suffering chronic pain hope manage better   \n",
       "...                                                 ...   \n",
       "1393  practicing mindfulness since mid also teaching...   \n",
       "1394  taking course pre requisite breathworks course...   \n",
       "1395  would like attend breathworks training given c...   \n",
       "1396  meditating two year inconsistently using cd bo...   \n",
       "1397  work support worker community mental health te...   \n",
       "\n",
       "               ReferralSource Daily20MPractice  CourseDate CourseType  \\\n",
       "0                     website                   2024-04-03       OMfH   \n",
       "1             internet search                   2024-06-02       OMfH   \n",
       "2             internet search                   2024-03-07       OMfH   \n",
       "3         work work colleague                   2024-03-07       OMfH   \n",
       "4                        book                   2024-03-07       OMfH   \n",
       "...                       ...              ...         ...        ...   \n",
       "1393                  website              nan  2015-01-12       OMfH   \n",
       "1394  friend family colleague              nan  2015-01-12       OMfH   \n",
       "1395  friend family colleague              nan  2015-01-12       OMfH   \n",
       "1396                  website              nan  2015-02-02       OMfH   \n",
       "1397                  website              nan  2015-01-12       OMfH   \n",
       "\n",
       "     EnrollmentDate  Gender  \\\n",
       "0        2024-02-22  Female   \n",
       "1        2024-02-22  Female   \n",
       "2        2024-02-20  Female   \n",
       "3        2024-02-20  Female   \n",
       "4        2024-02-19  Female   \n",
       "...             ...     ...   \n",
       "1393     2014-12-12     NaN   \n",
       "1394     2014-12-12     NaN   \n",
       "1395     2014-12-10     NaN   \n",
       "1396     2014-11-24     NaN   \n",
       "1397     2014-11-16     NaN   \n",
       "\n",
       "                                              Ethnicity         DoB  \\\n",
       "0     White (including White British, Irish, Gypsy o...  08/03/1967   \n",
       "1     White (including White British, Irish, Gypsy o...  29/11/1981   \n",
       "2     White (including White British, Irish, Gypsy o...  07/03/1975   \n",
       "3     White (including White British, Irish, Gypsy o...  09/06/1974   \n",
       "4     White (including White British, Irish, Gypsy o...  03/09/1966   \n",
       "...                                                 ...         ...   \n",
       "1393                                                NaN         NaN   \n",
       "1394                                                NaN         NaN   \n",
       "1395                                                NaN         NaN   \n",
       "1396                                                NaN         NaN   \n",
       "1397                                                NaN         NaN   \n",
       "\n",
       "                        Location  \\\n",
       "0     Magdalen Square, Liverpool   \n",
       "1                            NaN   \n",
       "2                            NaN   \n",
       "3                     Merseyside   \n",
       "4                            NaN   \n",
       "...                          ...   \n",
       "1393                         NaN   \n",
       "1394                         NaN   \n",
       "1395                         NaN   \n",
       "1396                         NaN   \n",
       "1397                         NaN   \n",
       "\n",
       "                                         Communications  \n",
       "0     Ongoing support communications sign up, I woul...  \n",
       "1     Ongoing support communications sign up, I woul...  \n",
       "2                Ongoing support communications sign up  \n",
       "3     Ongoing support communications sign up, I woul...  \n",
       "4                                                   NaN  \n",
       "...                                                 ...  \n",
       "1393                                                NaN  \n",
       "1394                                                NaN  \n",
       "1395                                                NaN  \n",
       "1396                                                NaN  \n",
       "1397                                                NaN  \n",
       "\n",
       "[1398 rows x 12 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = pd.DataFrame(df_transformed, columns=transformed_columns)\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df_cleaned.drop(columns=non_textual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonalHistory</th>\n",
       "      <th>Motivation</th>\n",
       "      <th>ReferralSource</th>\n",
       "      <th>Daily20MPractice</th>\n",
       "      <th>Communications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>issue fatigue stress currently identify chroni...</td>\n",
       "      <td>occupational therapist working nh patient long...</td>\n",
       "      <td>website</td>\n",
       "      <td></td>\n",
       "      <td>Ongoing support communications sign up, I woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>migraine disc hernia neck undiagnosed knee pai...</td>\n",
       "      <td>joining course hope cn find useful technique h...</td>\n",
       "      <td>internet search</td>\n",
       "      <td></td>\n",
       "      <td>Ongoing support communications sign up, I woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>auto immune issue experience frequent gastric ...</td>\n",
       "      <td>always high stress consistently advised someth...</td>\n",
       "      <td>internet search</td>\n",
       "      <td></td>\n",
       "      <td>Ongoing support communications sign up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fm long covid experienced persistent pain last...</td>\n",
       "      <td>looking forward joining course fm also long co...</td>\n",
       "      <td>work work colleague</td>\n",
       "      <td></td>\n",
       "      <td>Ongoing support communications sign up, I woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>experienced persistent pain lasted least last ...</td>\n",
       "      <td>suffering chronic pain hope manage better</td>\n",
       "      <td>book</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>currently identify chronic pain condition</td>\n",
       "      <td>practicing mindfulness since mid also teaching...</td>\n",
       "      <td>website</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>currently identify chronic pain condition</td>\n",
       "      <td>taking course pre requisite breathworks course...</td>\n",
       "      <td>friend family colleague</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>currently identify chronic pain condition</td>\n",
       "      <td>would like attend breathworks training given c...</td>\n",
       "      <td>friend family colleague</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>currently identify chronic pain condition</td>\n",
       "      <td>meditating two year inconsistently using cd bo...</td>\n",
       "      <td>website</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>currently identify chronic pain condition</td>\n",
       "      <td>work support worker community mental health te...</td>\n",
       "      <td>website</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1398 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        PersonalHistory  \\\n",
       "0     issue fatigue stress currently identify chroni...   \n",
       "1     migraine disc hernia neck undiagnosed knee pai...   \n",
       "2     auto immune issue experience frequent gastric ...   \n",
       "3     fm long covid experienced persistent pain last...   \n",
       "4     experienced persistent pain lasted least last ...   \n",
       "...                                                 ...   \n",
       "1393          currently identify chronic pain condition   \n",
       "1394          currently identify chronic pain condition   \n",
       "1395          currently identify chronic pain condition   \n",
       "1396          currently identify chronic pain condition   \n",
       "1397          currently identify chronic pain condition   \n",
       "\n",
       "                                             Motivation  \\\n",
       "0     occupational therapist working nh patient long...   \n",
       "1     joining course hope cn find useful technique h...   \n",
       "2     always high stress consistently advised someth...   \n",
       "3     looking forward joining course fm also long co...   \n",
       "4             suffering chronic pain hope manage better   \n",
       "...                                                 ...   \n",
       "1393  practicing mindfulness since mid also teaching...   \n",
       "1394  taking course pre requisite breathworks course...   \n",
       "1395  would like attend breathworks training given c...   \n",
       "1396  meditating two year inconsistently using cd bo...   \n",
       "1397  work support worker community mental health te...   \n",
       "\n",
       "               ReferralSource Daily20MPractice  \\\n",
       "0                     website                    \n",
       "1             internet search                    \n",
       "2             internet search                    \n",
       "3         work work colleague                    \n",
       "4                        book                    \n",
       "...                       ...              ...   \n",
       "1393                  website              nan   \n",
       "1394  friend family colleague              nan   \n",
       "1395  friend family colleague              nan   \n",
       "1396                  website              nan   \n",
       "1397                  website              nan   \n",
       "\n",
       "                                         Communications  \n",
       "0     Ongoing support communications sign up, I woul...  \n",
       "1     Ongoing support communications sign up, I woul...  \n",
       "2                Ongoing support communications sign up  \n",
       "3     Ongoing support communications sign up, I woul...  \n",
       "4                                                   NaN  \n",
       "...                                                 ...  \n",
       "1393                                                NaN  \n",
       "1394                                                NaN  \n",
       "1395                                                NaN  \n",
       "1396                                                NaN  \n",
       "1397                                                NaN  \n",
       "\n",
       "[1398 rows x 5 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       issue fatigue stress currently identify chroni...\n",
       "1       migraine disc hernia neck undiagnosed knee pai...\n",
       "2       auto immune issue experience frequent gastric ...\n",
       "3       fm long covid experienced persistent pain last...\n",
       "4       experienced persistent pain lasted least last ...\n",
       "                              ...                        \n",
       "1393            currently identify chronic pain condition\n",
       "1394            currently identify chronic pain condition\n",
       "1395            currently identify chronic pain condition\n",
       "1396            currently identify chronic pain condition\n",
       "1397            currently identify chronic pain condition\n",
       "Name: PersonalHistory, Length: 1398, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "df_dropped.PersonalHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model, vectorizer, num_topics=3, num_words=10):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names_out()[i], topic[i])\n",
    "               for i in topic.argsort()[:-num_words - 1:-1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!***~owo~_____________Topics for PersonalHistory:______________~owo~***!!!\n",
      "Topic 0:\n",
      "[('no', 1278.5176865947878), ('condition', 1234.770191432579), ('don', 1224.6630685452412), ('chronic', 1214.56581976115), ('as', 1177.6361010073347), ('currently', 1171.139067297414), ('having', 1170.136342778875), ('identify', 1151.04518953096), ('pain', 1107.9812979853448), ('none', 17.171189481030193)]\n",
      "Topic 1:\n",
      "[('or', 436.21233553146703), ('depression', 261.3022154633636), ('health', 246.11451454998672), ('mental', 238.45449750350954), ('acute', 229.29154181766873), ('pain', 228.89819059255817), ('debilitating', 224.47089435761296), ('experience', 223.46187192984056), ('other', 221.42972120240455), ('any', 211.4599299741606)]\n",
      "Topic 2:\n",
      "[('and', 924.0229084276606), ('the', 692.171150773056), ('have', 638.5834408659448), ('to', 569.0812238148733), ('my', 477.7134232451674), ('pain', 457.120511422088), ('of', 439.8763404826158), ('in', 347.7425367414486), ('for', 345.6898726294539), ('with', 340.453508676811)]\n",
      "!!!***~owo~_____________Topics for Motivation:______________~owo~***!!!\n",
      "Topic 0:\n",
      "[('trainer', 11.000360811333824), ('established', 7.244004027072983), ('2012', 5.288658573374003), ('deteriorating', 4.093818490259909), ('persistent', 4.024679054953837), ('leg', 3.673792757198389), ('medical', 3.6728842449308003), ('asdf', 3.332611212840814), ('brazil', 3.3307470396842986), ('tai', 3.313639707302928)]\n",
      "Topic 1:\n",
      "[('to', 463.6237103978496), ('and', 297.1044840749308), ('pain', 276.75295869014866), ('my', 189.79208325513625), ('with', 180.06251503525132), ('of', 168.44790285422323), ('chronic', 119.29042183528017), ('in', 102.70795771934748), ('learn', 97.72520775179211), ('better', 91.78664751102575)]\n",
      "Topic 2:\n",
      "[('to', 2856.961714752095), ('and', 2254.001807711446), ('the', 1603.7131042878227), ('my', 1225.8584843627837), ('in', 1030.9385336519454), ('have', 920.1836271566692), ('mindfulness', 889.2529279762648), ('with', 840.5775150780962), ('of', 739.8961690991273), ('course', 719.6714970930224)]\n",
      "!!!***~owo~_____________Topics for ReferralSource:______________~owo~***!!!\n",
      "Topic 0:\n",
      "[('website', 308.3199360895393), ('search', 218.32930332582194), ('internet', 217.33113610827291), ('other', 149.32570064012788), ('work', 95.29877775693747), ('teacher', 16.232719605451525), ('nan', 8.328508429534052), ('therapist', 7.330222046363864), ('charity', 7.32055157614814), ('mbsr', 6.268489531663259)]\n",
      "Topic 1:\n",
      "[('member', 150.69377339369763), ('hospital', 64.33048732074663), ('doctor', 63.33109651637897), ('event', 36.32865559964079), ('mindfulness', 36.283588677816375), ('the', 30.32482349198828), ('for', 29.329613508821584), ('book', 26.329171221023252), ('vidyamala', 26.32671220120813), ('in', 24.288086139534286)]\n",
      "Topic 2:\n",
      "[('friend', 330.3152102680611), ('family', 329.3166176200233), ('colleague', 228.31092370811015), ('group', 14.30152614955763), ('support', 13.322999635161779), ('insight', 9.31267433818623), ('timer', 9.312674338186168), ('triratna', 5.145314503770313), ('living', 3.473572844200902), ('illness', 3.473572583038946)]\n",
      "!!!***~owo~_____________Topics for Daily20MPractice:______________~owo~***!!!\n",
      "Topic 0:\n",
      "[('to', 132.06600673761648), ('the', 85.05731943570616), ('and', 61.72639107958161), ('be', 40.28808647602793), ('this', 37.42837471339351), ('for', 36.486113887856135), ('will', 35.234860948353386), ('of', 34.13054991118625), ('my', 32.83658846846718), ('so', 30.969975827432297)]\n",
      "Topic 1:\n",
      "[('nan', 707.3287957781993), ('practice', 33.85955527914793), ('mindfulness', 25.056149377407728), ('for', 20.988146379212207), ('daily', 20.15948371403328), ('day', 18.583758516524128), ('and', 14.970251060942758), ('meditation', 14.555982321382814), ('to', 13.34279119379403), ('have', 12.973498318237727)]\n",
      "Topic 2:\n",
      "[('yes', 630.4979675811416), ('am', 28.0735253191641), ('have', 26.620014926007407), ('and', 21.303357859474502), ('do', 14.251938019260727), ('with', 14.206883355287857), ('already', 13.556485212448775), ('so', 11.815914107194168), ('it', 10.575198897128379), ('meditation', 10.418515061670597)]\n"
     ]
    }
   ],
   "source": [
    "for column in textual:\n",
    "    # Transform the data\n",
    "    data_vectorized = vectorizer.fit_transform(df[column].values.astype('U'))\n",
    "\n",
    "    # Initialize and fit the LDA model\n",
    "    lda_model = LatentDirichletAllocation(n_components=3, random_state=0)\n",
    "    lda_vectors = lda_model.fit_transform(data_vectorized)\n",
    "\n",
    "    # Print the topics found by the LDA model\n",
    "    print(f\"____________________Topics for {column}:_____________________\")\n",
    "    print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\"I am looking for more help with my a connection between my mind and body, and maybe for someone to teach me ways to stay more calm and mindfull, i don't suffer from that much physical pain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

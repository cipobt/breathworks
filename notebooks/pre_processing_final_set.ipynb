{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/aryavachin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/aryavachin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/aryavachin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/aryavachin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Data Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "# Pipeline and Column Transformers\n",
    "from sklearn import set_config\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Unsupervised Learning\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# STATISTICS\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "# Text Processing\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# NLTK Downloads\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Set pandas display option\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Set sklearn display configuration\n",
    "set_config(display = \"diagram\")\n",
    "\n",
    "# Custom Transformers and Model Building\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['CourseType', 'Gender', 'Ethnicity']\n",
    "datetime_columns = ['AgeAtCourse']\n",
    "non_textual = categorical_columns + datetime_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/aryavachin/code/cipobt/breathWorks')\n",
    "from breathworks.utils import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
      "/home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/plotly/express/imshow_utils.py:24: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  np.bool8: (False, True),\n"
     ]
    }
   ],
   "source": [
    "from breathworks.clustering.preprocessing import build_preprocessor, simple_preprocessor_with_topics\n",
    "from breathworks.clustering.cleaning import clean_data, clean_textual_columns\n",
    "from breathworks.clustering.LDA import splitting_into_topics, lda_visual\n",
    "from breathworks.clustering.plots import corr_plot, plot_clusters, plot_clusters_2d, plot_clusters_3d\n",
    "from breathworks.clustering.clustering import label_dataframe, fit_kmeans_and_label, plot_lda\n",
    "from breathworks.clustering.config import drop_columns, textual_columns, categorical_columns, datetime_columns, to_drop, topics_per_column, column_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fetch and clean data\n",
    "# dataframe = get_data()\n",
    "# processed_data = clean_data(dataframe,drop_columns)\n",
    "# df_transformed = clean_textual_columns(processed_data, textual_columns)\n",
    "\n",
    "# # # Apply filters\n",
    "# # df_filtered = df_transformed[(df_transformed['Gender'] == 'Male') &\n",
    "# #                              (df_transformed['CourseType'].isin(['OMfH','OMfH'])) &\n",
    "# #                              (df_transformed['Ethnicity'] == 'White')]\n",
    "\n",
    "# # Apply the transformations for LDA\n",
    "# df_transformed = df_transformed.drop(columns=to_drop)\n",
    "# df_split = splitting_into_topics(df_transformed,topics_per_column,textual_columns)\n",
    "# preprocessor = build_preprocessor(textual_columns, categorical_columns, datetime_columns)\n",
    "# df_LDA = preprocessor.fit_transform(df_split)\n",
    "\n",
    "# # final df with correct column names\n",
    "# transformed_columns = preprocessor.get_feature_names_out()\n",
    "# df_final = pd.DataFrame(df_LDA, columns=transformed_columns)\n",
    "# df_final = df_final.apply(pd.to_numeric)\n",
    "\n",
    "# # df_2d = df_final[[col1b,col2a]]\n",
    "# # labelling = fit_kmeans_and_label(df_2d,4)\n",
    "# # label_dataframe(df_2d, labelling)\n",
    "\n",
    "# # print the clusters with their labels\n",
    "# plot_lda(df_final,column_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/frame.py:706: DeprecationWarning: Passing a BlockManager to DataFrame is deprecated and will raise in a future version. Use public APIs instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# get the data\n",
    "dataframe = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3242 entries, 0 to 3241\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   CourseDate       3242 non-null   object\n",
      " 1   CourseType       3242 non-null   object\n",
      " 2   Gender           3242 non-null   object\n",
      " 3   Ethnicity        3242 non-null   object\n",
      " 4   AgeAtCourse      3242 non-null   int64 \n",
      " 5   CustomerPurpose  3242 non-null   object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 152.1+ KB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CourseDate</th>\n",
       "      <th>CourseType</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>AgeAtCourse</th>\n",
       "      <th>CustomerPurpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>IMfS</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>21</td>\n",
       "      <td>I would like to learn more and practice mindfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>IMfS</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>22</td>\n",
       "      <td>I would like to understand mindfulness to a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>IMfS</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>22</td>\n",
       "      <td>To establish a greater understanding of mindfu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CourseDate CourseType Gender Ethnicity  AgeAtCourse  \\\n",
       "0  2017-03-12       IMfS   Male     White           21   \n",
       "1  2017-03-12       IMfS   Male     White           22   \n",
       "2  2017-03-12       IMfS   Male     White           22   \n",
       "\n",
       "                                     CustomerPurpose  \n",
       "0  I would like to learn more and practice mindfu...  \n",
       "1  I would like to understand mindfulness to a gr...  \n",
       "2  To establish a greater understanding of mindfu...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed = dataframe\n",
    "\n",
    "df_transformed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CourseDate         0\n",
       "CourseType         0\n",
       "Gender             0\n",
       "Ethnicity          0\n",
       "AgeAtCourse        0\n",
       "CustomerPurpose    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "textual_columns = ['CustomerPurpose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the df\n",
    "in_person = ['IMfH', 'IMfS', 'I5DMfH']\n",
    "online = ['OMfH', 'OMfS']\n",
    "all_course_types = in_person + online\n",
    "to_drop = ['Gender', 'CourseType', 'Ethnicity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [column for column in categorical_columns if column not in to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_per_column = {\n",
    "    'CustomerPurpose': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Apply the transformations for LDA\n",
    "df_transformed = df_transformed.drop(columns=to_drop, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerPurpose - Topic 0:\n",
      "[('qualify for', 1.804751341941321), ('to qualify', 1.684866080060762), ('qualify', 1.6848660785126062), ('family bereavement', 1.2765949466909667), ('cease', 1.2082717707749298), ('bereavement', 1.1766814202977445), ('better work', 1.0340927141483693), ('consciousness', 0.9827397918094816), ('suggest', 0.9145874338024798), ('automatic', 0.8773522078824001)]\n",
      "CustomerPurpose - Topic 1:\n",
      "[('resilience', 1.2899200693870883), ('curiosity', 1.2010574085168428), ('ssnhl', 1.0836057625395716), ('provided', 1.0130845413182068), ('from friend', 1.009113597302867), ('and happiness', 1.004846506790354), ('anxiety only', 0.9995474907611517), ('msbr', 0.9689400591967874), ('msbr course', 0.9689400591967823), ('glasses', 0.9654248890031432)]\n",
      "CustomerPurpose - Topic 2:\n",
      "[('and', 131.62086759625828), ('to', 120.25150906920555), ('the', 93.38864629992732), ('have', 84.76912241635966), ('my', 79.72959679732874), ('in', 71.14869673009154), ('of', 67.70279735477256), ('pain', 62.60979115934203), ('with', 61.01920519759385), ('for', 56.86220270437149)]\n",
      "CustomerPurpose - Topic 3:\n",
      "[('to', 76.58630145904387), ('and', 55.39501181601202), ('mindfulness', 43.02161973690873), ('the', 40.008929971597674), ('teacher', 37.79489043802355), ('pain', 37.085074527796486), ('my', 34.983106004798906), ('in', 32.00828446110141), ('training', 31.98302833813504), ('do', 30.275769190739798)]\n",
      "CustomerPurpose - Topic 4:\n",
      "[('asdf', 1.5095710523265156), ('anxiety anxiety', 1.4108224275993404), ('marketing', 1.2040932107962872), ('curiosity about', 1.09555267585582), ('breathworks methods', 0.828594380412041), ('refreshing', 0.8065331360738279), ('to establish', 0.7959451253584167), ('have filled', 0.7722285459331846), ('establish solid', 0.771124631741007), ('and secular', 0.771124631741007)]\n"
     ]
    }
   ],
   "source": [
    "# # Assuming 'splitting_into_topics' and 'build_preprocessor' are predefined functions\n",
    "# df_split, lda_details = splitting_into_topics(df_transformed, topics_per_column, textual_columns)\n",
    "# preprocessor = build_preprocessor(textual_columns, categorical_columns, datetime_columns)\n",
    "# df_LDA = preprocessor.fit_transform(df_split)\n",
    "\n",
    "df_split, lda_details = splitting_into_topics(df_transformed, topics_per_column, textual_columns)\n",
    "\n",
    "# Update textual_columns to reflect the new LDA topic columns\n",
    "new_textual_columns = []\n",
    "for text_column in textual_columns:\n",
    "    num_topics = topics_per_column[text_column]\n",
    "    new_textual_columns.extend([f'{text_column}_Topic{i}' for i in range(num_topics)])\n",
    "\n",
    "# Now new_textual_columns contains the new column names generated from LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'CourseType' not in df_split.columns, \"'CourseType' still exists in df_split\"\n",
    "assert 'CourseType' not in categorical_columns, \"'CourseType' still exists in categorical_columns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CourseDate</th>\n",
       "      <th>CourseType</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>AgeAtCourse</th>\n",
       "      <th>CustomerPurpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>IMfS</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>21</td>\n",
       "      <td>I would like to learn more and practice mindfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>IMfS</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>22</td>\n",
       "      <td>I would like to understand mindfulness to a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>IMfS</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>22</td>\n",
       "      <td>To establish a greater understanding of mindfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-06</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>22</td>\n",
       "      <td>To help me manage the severe ibs pain I have s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>IMfS</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>23</td>\n",
       "      <td>Recently exited a long term relationship ; as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>White</td>\n",
       "      <td>48</td>\n",
       "      <td>Partly personally and professionally . Persona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Other</td>\n",
       "      <td>51</td>\n",
       "      <td>I have chronic pain , which I 'd like to manag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>2021-10-05</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>asdfasdf fdbx I have experienced persistent pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>White</td>\n",
       "      <td>53</td>\n",
       "      <td>fds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>2022-09-25</td>\n",
       "      <td>OMfS</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Other</td>\n",
       "      <td>54</td>\n",
       "      <td>To begin a regular mindfulness practice and le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3242 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CourseDate CourseType             Gender Ethnicity  AgeAtCourse  \\\n",
       "0     2017-03-12       IMfS               Male     White           21   \n",
       "1     2017-03-12       IMfS               Male     White           22   \n",
       "2     2017-03-12       IMfS               Male     White           22   \n",
       "3     2024-02-06       OMfH               Male     White           22   \n",
       "4     2019-04-27       IMfS               Male     Other           23   \n",
       "...          ...        ...                ...       ...          ...   \n",
       "3237  2019-01-14       OMfH  Prefer not to say     White           48   \n",
       "3238  2022-05-03       OMfH  Prefer not to say     Other           51   \n",
       "3239  2021-10-05       OMfH  Prefer not to say     Asian           52   \n",
       "3240  2016-09-05       OMfH  Prefer not to say     White           53   \n",
       "3241  2022-09-25       OMfS  Prefer not to say     Other           54   \n",
       "\n",
       "                                        CustomerPurpose  \n",
       "0     I would like to learn more and practice mindfu...  \n",
       "1     I would like to understand mindfulness to a gr...  \n",
       "2     To establish a greater understanding of mindfu...  \n",
       "3     To help me manage the severe ibs pain I have s...  \n",
       "4     Recently exited a long term relationship ; as ...  \n",
       "...                                                 ...  \n",
       "3237  Partly personally and professionally . Persona...  \n",
       "3238  I have chronic pain , which I 'd like to manag...  \n",
       "3239  asdfasdf fdbx I have experienced persistent pa...  \n",
       "3240                                                fds  \n",
       "3241  To begin a regular mindfulness practice and le...  \n",
       "\n",
       "[3242 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(ngram_range=(1, 2), stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;lda&#x27;, LatentDirichletAllocation(n_components=5))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(ngram_range=(1, 2), stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;lda&#x27;, LatentDirichletAllocation(n_components=5))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(1, 2), stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(n_components=5)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
       "                ('lda', LatentDirichletAllocation(n_components=5))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = build_preprocessor()\n",
    "preprocessor\n",
    "# df_LDA = preprocessor.fit_transform(df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CourseDate</th>\n",
       "      <th>CourseType</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>AgeAtCourse</th>\n",
       "      <th>CustomerPurpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>IMfS</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>21</td>\n",
       "      <td>I would like to learn more and practice mindfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>IMfS</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>22</td>\n",
       "      <td>I would like to understand mindfulness to a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>IMfS</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>22</td>\n",
       "      <td>To establish a greater understanding of mindfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-06</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>22</td>\n",
       "      <td>To help me manage the severe ibs pain I have s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>IMfS</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>23</td>\n",
       "      <td>Recently exited a long term relationship ; as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>White</td>\n",
       "      <td>48</td>\n",
       "      <td>Partly personally and professionally . Persona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Other</td>\n",
       "      <td>51</td>\n",
       "      <td>I have chronic pain , which I 'd like to manag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>2021-10-05</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>asdfasdf fdbx I have experienced persistent pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>OMfH</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>White</td>\n",
       "      <td>53</td>\n",
       "      <td>fds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>2022-09-25</td>\n",
       "      <td>OMfS</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Other</td>\n",
       "      <td>54</td>\n",
       "      <td>To begin a regular mindfulness practice and le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3242 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CourseDate CourseType             Gender Ethnicity  AgeAtCourse  \\\n",
       "0     2017-03-12       IMfS               Male     White           21   \n",
       "1     2017-03-12       IMfS               Male     White           22   \n",
       "2     2017-03-12       IMfS               Male     White           22   \n",
       "3     2024-02-06       OMfH               Male     White           22   \n",
       "4     2019-04-27       IMfS               Male     Other           23   \n",
       "...          ...        ...                ...       ...          ...   \n",
       "3237  2019-01-14       OMfH  Prefer not to say     White           48   \n",
       "3238  2022-05-03       OMfH  Prefer not to say     Other           51   \n",
       "3239  2021-10-05       OMfH  Prefer not to say     Asian           52   \n",
       "3240  2016-09-05       OMfH  Prefer not to say     White           53   \n",
       "3241  2022-09-25       OMfS  Prefer not to say     Other           54   \n",
       "\n",
       "                                        CustomerPurpose  \n",
       "0     I would like to learn more and practice mindfu...  \n",
       "1     I would like to understand mindfulness to a gr...  \n",
       "2     To establish a greater understanding of mindfu...  \n",
       "3     To help me manage the severe ibs pain I have s...  \n",
       "4     Recently exited a long term relationship ; as ...  \n",
       "...                                                 ...  \n",
       "3237  Partly personally and professionally . Persona...  \n",
       "3238  I have chronic pain , which I 'd like to manag...  \n",
       "3239  asdfasdf fdbx I have experienced persistent pa...  \n",
       "3240                                                fds  \n",
       "3241  To begin a regular mindfulness practice and le...  \n",
       "\n",
       "[3242 rows x 6 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_distribution topic_label\n",
      "0    45.589143\n",
      "1    39.543492\n",
      "2    14.867366\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "topic_labelled_df, topic_only_df = simple_preprocessor_with_topics(dataframe, 'CustomerPurpose', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>topic_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerPurpose</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learn practice mindfulness study briefly year</th>\n",
       "      <td>0.056396</td>\n",
       "      <td>0.054317</td>\n",
       "      <td>0.057577</td>\n",
       "      <td>0.774499</td>\n",
       "      <td>0.057211</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>understand mindfulness great extend use idea technique see situation objectively possible</th>\n",
       "      <td>0.803508</td>\n",
       "      <td>0.048228</td>\n",
       "      <td>0.049993</td>\n",
       "      <td>0.048539</td>\n",
       "      <td>0.049732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>establish great understand mindfulness order good equip use technique idea</th>\n",
       "      <td>0.042660</td>\n",
       "      <td>0.041835</td>\n",
       "      <td>0.830183</td>\n",
       "      <td>0.042059</td>\n",
       "      <td>0.043263</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help manage severe ibs pain suffer year irritable bowel syndrome anxiety depression panic attack adhd experience persistent pain last least last month anxiety depression</th>\n",
       "      <td>0.871835</td>\n",
       "      <td>0.031636</td>\n",
       "      <td>0.032124</td>\n",
       "      <td>0.032317</td>\n",
       "      <td>0.032087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recently exit long term relationship result experience intense clarity mind acute awareness miss significantly great attention connection emotion aspiration consciousness awareness self others attend mindfulness session weekly basis university student learn body scan cultivate love kindness calm mind focus breath sound touch eye open shut deepen meditative practice deeply personally important grow person spiritually mentally emotionally please consider acceptance application thank</th>\n",
       "      <td>0.910920</td>\n",
       "      <td>0.021976</td>\n",
       "      <td>0.022360</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partly personally professionally personally help deal stressful situation professionally become teacher breathworks future pre requisite course</th>\n",
       "      <td>0.038850</td>\n",
       "      <td>0.038091</td>\n",
       "      <td>0.844136</td>\n",
       "      <td>0.038195</td>\n",
       "      <td>0.040727</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chronic pain manage along learn pace activity rheumatoid arthritis degenerative disc disease tinnitus experience persistent pain last least last month n experience acute debilitate depression mental health condition</th>\n",
       "      <td>0.397907</td>\n",
       "      <td>0.029659</td>\n",
       "      <td>0.511797</td>\n",
       "      <td>0.030411</td>\n",
       "      <td>0.030227</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fdbx experience persistent pain last least last month</th>\n",
       "      <td>0.057023</td>\n",
       "      <td>0.055668</td>\n",
       "      <td>0.056576</td>\n",
       "      <td>0.773964</td>\n",
       "      <td>0.056769</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fds</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>begin regular mindfulness practice learn different tool use especially feel anxious particular social anxiety friend tell course may wish late breathworks teacher train base experience practice initial course potentially count towards pre requisite require late stage say mild moderate especially lot go work project</th>\n",
       "      <td>0.025961</td>\n",
       "      <td>0.192339</td>\n",
       "      <td>0.731524</td>\n",
       "      <td>0.024607</td>\n",
       "      <td>0.025569</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3242 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           0         1  \\\n",
       "CustomerPurpose                                                          \n",
       "learn practice mindfulness study briefly year       0.056396  0.054317   \n",
       "understand mindfulness great extend use idea te...  0.803508  0.048228   \n",
       "establish great understand mindfulness order go...  0.042660  0.041835   \n",
       "help manage severe ibs pain suffer year irritab...  0.871835  0.031636   \n",
       "recently exit long term relationship result exp...  0.910920  0.021976   \n",
       "...                                                      ...       ...   \n",
       "partly personally professionally personally hel...  0.038850  0.038091   \n",
       "chronic pain manage along learn pace activity r...  0.397907  0.029659   \n",
       "fdbx experience persistent pain last least last...  0.057023  0.055668   \n",
       "fds                                                 0.200000  0.200000   \n",
       "begin regular mindfulness practice learn differ...  0.025961  0.192339   \n",
       "\n",
       "                                                           2         3  \\\n",
       "CustomerPurpose                                                          \n",
       "learn practice mindfulness study briefly year       0.057577  0.774499   \n",
       "understand mindfulness great extend use idea te...  0.049993  0.048539   \n",
       "establish great understand mindfulness order go...  0.830183  0.042059   \n",
       "help manage severe ibs pain suffer year irritab...  0.032124  0.032317   \n",
       "recently exit long term relationship result exp...  0.022360  0.022058   \n",
       "...                                                      ...       ...   \n",
       "partly personally professionally personally hel...  0.844136  0.038195   \n",
       "chronic pain manage along learn pace activity r...  0.511797  0.030411   \n",
       "fdbx experience persistent pain last least last...  0.056576  0.773964   \n",
       "fds                                                 0.200000  0.200000   \n",
       "begin regular mindfulness practice learn differ...  0.731524  0.024607   \n",
       "\n",
       "                                                           4  topic_label  \n",
       "CustomerPurpose                                                            \n",
       "learn practice mindfulness study briefly year       0.057211            3  \n",
       "understand mindfulness great extend use idea te...  0.049732            0  \n",
       "establish great understand mindfulness order go...  0.043263            2  \n",
       "help manage severe ibs pain suffer year irritab...  0.032087            0  \n",
       "recently exit long term relationship result exp...  0.022687            0  \n",
       "...                                                      ...          ...  \n",
       "partly personally professionally personally hel...  0.040727            2  \n",
       "chronic pain manage along learn pace activity r...  0.030227            2  \n",
       "fdbx experience persistent pain last least last...  0.056769            3  \n",
       "fds                                                 0.200000            0  \n",
       "begin regular mindfulness practice learn differ...  0.025569            2  \n",
       "\n",
       "[3242 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_labelled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distribution</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.589143</td>\n",
       "      <td>'mindfulness''course''teacher''train''practice''teacher train''breathworks''meditation''teach''stress'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.543492</td>\n",
       "      <td>'pain''chronic''condition''chronic pain''pain condition''identify''currently''identify chronic''currently identify''experience'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.867366</td>\n",
       "      <td>'stress''work''anxiety''mindfulness''life''depression''stress work''recommend''help''job'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Distribution  \\\n",
       "0     45.589143   \n",
       "1     39.543492   \n",
       "2     14.867366   \n",
       "\n",
       "                                                                                                                          Keywords  \n",
       "0                           'mindfulness''course''teacher''train''practice''teacher train''breathworks''meditation''teach''stress'  \n",
       "1  'pain''chronic''condition''chronic pain''pain condition''identify''currently''identify chronic''currently identify''experience'  \n",
       "2                                        'stress''work''anxiety''mindfulness''life''depression''stress work''recommend''help''job'  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 500)\n",
    "topic_only_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only if you want to save this\n",
    "topic_only_df.to_csv('maybe_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_labelled_df.to_csv('maybe_3_topic_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_avatars = pd.read_csv('maybe_3_topic_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_avatars_topic_only_df = pd.read_csv('maybe_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerPurpose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>topic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>learn practice mindfulness study briefly</td>\n",
       "      <td>0.656668</td>\n",
       "      <td>0.098584</td>\n",
       "      <td>0.244748</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>understand mindfulness great extend use idea t...</td>\n",
       "      <td>0.818987</td>\n",
       "      <td>0.092523</td>\n",
       "      <td>0.088489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>establish great understand mindfulness order g...</td>\n",
       "      <td>0.527297</td>\n",
       "      <td>0.082640</td>\n",
       "      <td>0.390063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>help manage severe ibs pain suffer irritable b...</td>\n",
       "      <td>0.056013</td>\n",
       "      <td>0.886111</td>\n",
       "      <td>0.057876</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recently exit long term relationship result ex...</td>\n",
       "      <td>0.895908</td>\n",
       "      <td>0.063063</td>\n",
       "      <td>0.041029</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>partly personally professionally personally he...</td>\n",
       "      <td>0.549413</td>\n",
       "      <td>0.070180</td>\n",
       "      <td>0.380407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>chronic pain manage along learn pace activity ...</td>\n",
       "      <td>0.050209</td>\n",
       "      <td>0.899765</td>\n",
       "      <td>0.050026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>fdbx experience persistent pain last least las...</td>\n",
       "      <td>0.093855</td>\n",
       "      <td>0.812967</td>\n",
       "      <td>0.093178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>fds</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>begin regular mindfulness practice learn diffe...</td>\n",
       "      <td>0.908751</td>\n",
       "      <td>0.046634</td>\n",
       "      <td>0.044615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3242 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        CustomerPurpose         0         1  \\\n",
       "0              learn practice mindfulness study briefly  0.656668  0.098584   \n",
       "1     understand mindfulness great extend use idea t...  0.818987  0.092523   \n",
       "2     establish great understand mindfulness order g...  0.527297  0.082640   \n",
       "3     help manage severe ibs pain suffer irritable b...  0.056013  0.886111   \n",
       "4     recently exit long term relationship result ex...  0.895908  0.063063   \n",
       "...                                                 ...       ...       ...   \n",
       "3237  partly personally professionally personally he...  0.549413  0.070180   \n",
       "3238  chronic pain manage along learn pace activity ...  0.050209  0.899765   \n",
       "3239  fdbx experience persistent pain last least las...  0.093855  0.812967   \n",
       "3240                                                fds  0.333333  0.333333   \n",
       "3241  begin regular mindfulness practice learn diffe...  0.908751  0.046634   \n",
       "\n",
       "             2  topic_label  \n",
       "0     0.244748            0  \n",
       "1     0.088489            0  \n",
       "2     0.390063            0  \n",
       "3     0.057876            1  \n",
       "4     0.041029            0  \n",
       "...        ...          ...  \n",
       "3237  0.380407            0  \n",
       "3238  0.050026            1  \n",
       "3239  0.093178            1  \n",
       "3240  0.333333            0  \n",
       "3241  0.044615            0  \n",
       "\n",
       "[3242 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_avatars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Distribution</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45.589143</td>\n",
       "      <td>'mindfulness''course''teacher''train''practice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39.543492</td>\n",
       "      <td>'pain''chronic''condition''chronic pain''pain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14.867366</td>\n",
       "      <td>'stress''work''anxiety''mindfulness''life''dep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Distribution                                           Keywords\n",
       "0           0     45.589143  'mindfulness''course''teacher''train''practice...\n",
       "1           1     39.543492  'pain''chronic''condition''chronic pain''pain ...\n",
       "2           2     14.867366  'stress''work''anxiety''mindfulness''life''dep..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_avatars_topic_only_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopic\n",
      "  Downloading bertopic-0.16.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from bertopic) (1.24.4)\n",
      "Collecting hdbscan>=0.8.29 (from bertopic)\n",
      "  Downloading hdbscan-0.8.33.tar.gz (5.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting umap-learn>=0.5.0 (from bertopic)\n",
      "  Downloading umap-learn-0.5.5.tar.gz (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from bertopic) (2.2.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from bertopic) (1.3.2)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from bertopic) (4.66.2)\n",
      "Collecting sentence-transformers>=0.4.1 (from bertopic)\n",
      "  Downloading sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from bertopic) (5.9.0)\n",
      "Requirement already satisfied: cython<3,>=0.27 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (0.29.32)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (1.8.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2024.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from plotly>=4.7.0->bertopic) (8.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.34.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.16.4)\n",
      "Requirement already satisfied: Pillow in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (9.1.1)\n",
      "Collecting numba>=0.51.2 (from umap-learn>=0.5.0->bertopic)\n",
      "  Downloading numba-0.59.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting pynndescent>=0.5 (from umap-learn>=0.5.0->bertopic)\n",
      "  Downloading pynndescent-0.5.11-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.12.4)\n",
      "Requirement already satisfied: fsspec in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2022.10.0)\n",
      "Requirement already satisfied: requests in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (23.2)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba>=0.51.2->umap-learn>=0.5.0->bertopic)\n",
      "  Using cached llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Requirement already satisfied: sympy in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.12)\n",
      "Requirement already satisfied: networkx in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.8.7)\n",
      "Requirement already satisfied: jinja2 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.2.140)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (2022.9.13)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.14.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
      "Downloading bertopic-0.16.0-py2.py3-none-any.whl (154 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.59.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pynndescent-0.5.11-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\n",
      "Building wheels for collected packages: hdbscan, umap-learn\n",
      "  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hdbscan: filename=hdbscan-0.8.33-cp310-cp310-linux_x86_64.whl size=3667588 sha256=2ca8bb298b577eccab48629acb2933b1f3f34821acb15f54f2f8c8efa55faef0\n",
      "  Stored in directory: /home/aryavachin/.cache/pip/wheels/75/0b/3b/dc4f60b7cc455efaefb62883a7483e76f09d06ca81cf87d610\n",
      "  Building wheel for umap-learn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for umap-learn: filename=umap_learn-0.5.5-py3-none-any.whl size=86832 sha256=2b3bc79fb1db7cb1b2b00a5ffb87676d9c5d50eb34a2101ce6ebeee46d4f4cd9\n",
      "  Stored in directory: /home/aryavachin/.cache/pip/wheels/3a/70/07/428d2b58660a1a3b431db59b806a10da736612ebbc66c1bcc5\n",
      "Successfully built hdbscan umap-learn\n",
      "Installing collected packages: llvmlite, numba, pynndescent, hdbscan, umap-learn, sentence-transformers, bertopic\n",
      "Successfully installed bertopic-0.16.0 hdbscan-0.8.33 llvmlite-0.42.0 numba-0.59.1 pynndescent-0.5.11 sentence-transformers-2.6.1 umap-learn-0.5.5\n",
      "Requirement already satisfied: safetensors in /home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (0.3.3)\n",
      "Collecting safetensors\n",
      "  Using cached safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.3.3\n",
      "    Uninstalling safetensors-0.3.3:\n",
      "      Successfully uninstalled safetensors-0.3.3\n",
      "Successfully installed safetensors-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bertopic\n",
    "!pip install -U safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 18:59:12.939276: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-26 18:59:14.012381: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-26 18:59:14.273660: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-03-26 18:59:14.273702: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-03-26 18:59:14.473110: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-26 18:59:19.664557: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-26 18:59:19.667997: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-26 18:59:19.668124: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/plotly/graph_objs/__init__.py:288: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(ipywidgets.__version__) >= LooseVersion(\"7.0.0\"):\n",
      "/home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/plotly/graph_objs/__init__.py:288: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(ipywidgets.__version__) >= LooseVersion(\"7.0.0\"):\n",
      "/home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/plotly/graph_objs/__init__.py:288: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(ipywidgets.__version__) >= LooseVersion(\"7.0.0\"):\n",
      "/home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/plotly/graph_objs/__init__.py:288: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(ipywidgets.__version__) >= LooseVersion(\"7.0.0\"):\n",
      "/home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/skimage/util/dtype.py:27: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  np.bool8: (False, True),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>POS</th>\n",
       "      <th>KeyBERTInspired</th>\n",
       "      <th>MMR</th>\n",
       "      <th>KeyBERT + MMR</th>\n",
       "      <th>OpenAI_Label</th>\n",
       "      <th>OpenAI_Summary</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>14247</td>\n",
       "      <td>-1_language_models_model_data</td>\n",
       "      <td>[language, models, model, data, based, tasks, ...</td>\n",
       "      <td>[language, models, model, data, tasks, text, t...</td>\n",
       "      <td>[language processing, language models, embeddi...</td>\n",
       "      <td>[language, models, model, data, based, tasks, ...</td>\n",
       "      <td>[language processing, language models, embeddi...</td>\n",
       "      <td>[Advancements in Multilingual Language Models ...</td>\n",
       "      <td>[Pre-trained Language Models and Embeddings fo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1833</td>\n",
       "      <td>0_dialogue_dialog_response_responses</td>\n",
       "      <td>[dialogue, dialog, response, responses, intent...</td>\n",
       "      <td>[dialogue, dialog, response, responses, intent...</td>\n",
       "      <td>[task oriented dialogue, dialogue systems, ori...</td>\n",
       "      <td>[dialogue, dialog, response, responses, intent...</td>\n",
       "      <td>[task oriented dialogue, dialogue systems, ori...</td>\n",
       "      <td>[Challenges and Approaches in Developing Task-...</td>\n",
       "      <td>[Task-oriented dialogue systems and their comp...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1369</td>\n",
       "      <td>1_speech_asr_speech recognition_recognition</td>\n",
       "      <td>[speech, asr, speech recognition, recognition,...</td>\n",
       "      <td>[speech, recognition, acoustic, automatic spee...</td>\n",
       "      <td>[speech recognition asr, automatic speech, spe...</td>\n",
       "      <td>[speech, asr, speech recognition, recognition,...</td>\n",
       "      <td>[speech recognition asr, automatic speech, spe...</td>\n",
       "      <td>[Automatic Speech Recognition Systems for Mult...</td>\n",
       "      <td>[Speech recognition and transcription, includi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1109</td>\n",
       "      <td>2_tuning_tasks_prompt_models</td>\n",
       "      <td>[tuning, tasks, prompt, models, language, lang...</td>\n",
       "      <td>[tuning, tasks, prompt, models, language, trai...</td>\n",
       "      <td>[pre trained language, trained language models...</td>\n",
       "      <td>[tuning, tasks, prompt, models, language, lang...</td>\n",
       "      <td>[pre trained language, trained language models...</td>\n",
       "      <td>[Parameter-efficient fine-tuning of language m...</td>\n",
       "      <td>[Pre-trained language models and parameter-eff...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>893</td>\n",
       "      <td>3_summarization_summaries_summary_abstractive</td>\n",
       "      <td>[summarization, summaries, summary, abstractiv...</td>\n",
       "      <td>[summarization, summaries, summary, abstractiv...</td>\n",
       "      <td>[summarization models, summarization model, ab...</td>\n",
       "      <td>[summarization, summaries, summary, abstractiv...</td>\n",
       "      <td>[summarization models, summarization model, ab...</td>\n",
       "      <td>[Challenges in Abstractive Text Summarization ...</td>\n",
       "      <td>[Text Summarization Models and Systems\\n\\nThe ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>101</td>\n",
       "      <td>25</td>\n",
       "      <td>101_coherence_discourse_discourse coherence_co...</td>\n",
       "      <td>[coherence, discourse, discourse coherence, co...</td>\n",
       "      <td>[coherence, discourse, text, paragraph, models...</td>\n",
       "      <td>[discourse coherence, coherent text, coherence...</td>\n",
       "      <td>[coherence, discourse, discourse coherence, co...</td>\n",
       "      <td>[discourse coherence, coherent text, coherence...</td>\n",
       "      <td>[Coherence modeling in written and spoken disc...</td>\n",
       "      <td>[Modeling and Understanding Discourse Coherenc...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>102</td>\n",
       "      <td>25</td>\n",
       "      <td>102_pos_taggers_tagging_tagger</td>\n",
       "      <td>[pos, taggers, tagging, tagger, pos tagging, t...</td>\n",
       "      <td>[taggers, tagging, tagger, tags, tag, speech, ...</td>\n",
       "      <td>[speech tagging, speech pos tagging, tagged co...</td>\n",
       "      <td>[pos, taggers, tagging, tagger, pos tagging, t...</td>\n",
       "      <td>[speech tagging, speech pos tagging, tagged co...</td>\n",
       "      <td>[Challenges and Approaches in POS Tagging for ...</td>\n",
       "      <td>[This topic is focused on the importance of pa...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>103</td>\n",
       "      <td>24</td>\n",
       "      <td>103_drug_social_social media_media</td>\n",
       "      <td>[drug, social, social media, media, health, ad...</td>\n",
       "      <td>[drug, social, social media, media, health, ad...</td>\n",
       "      <td>[topic modeling, social media data, corpus, me...</td>\n",
       "      <td>[drug, social, social media, media, health, ad...</td>\n",
       "      <td>[topic modeling, social media data, corpus, me...</td>\n",
       "      <td>[Social Media and Drug Safety in Pharmacovigil...</td>\n",
       "      <td>[This topic revolves around the use of social ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>104</td>\n",
       "      <td>21</td>\n",
       "      <td>104_gender_translation_bias_gender bias</td>\n",
       "      <td>[gender, translation, bias, gender bias, mt, m...</td>\n",
       "      <td>[gender, translation, bias, grammatical gender...</td>\n",
       "      <td>[machine translation, neural machine translati...</td>\n",
       "      <td>[gender, translation, bias, gender bias, mt, m...</td>\n",
       "      <td>[machine translation, neural machine translati...</td>\n",
       "      <td>[Gender Bias in Machine Translation and Gender...</td>\n",
       "      <td>[This topic discusses gender-related issues in...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>105</td>\n",
       "      <td>20</td>\n",
       "      <td>105_job_resume_skills_skill</td>\n",
       "      <td>[job, resume, skills, skill, soft, resumes, ti...</td>\n",
       "      <td>[job, resume, skills, skill, soft, resumes, ti...</td>\n",
       "      <td>[resumes, job, information extraction, resume,...</td>\n",
       "      <td>[job, resume, skills, skill, soft, resumes, ti...</td>\n",
       "      <td>[resumes, job, information extraction, resume,...</td>\n",
       "      <td>[Machine Learning for Job and Resume Matching]</td>\n",
       "      <td>[Topic: Job Information Extraction and Classif...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                               Name  \\\n",
       "0       -1  14247                      -1_language_models_model_data   \n",
       "1        0   1833               0_dialogue_dialog_response_responses   \n",
       "2        1   1369        1_speech_asr_speech recognition_recognition   \n",
       "3        2   1109                       2_tuning_tasks_prompt_models   \n",
       "4        3    893      3_summarization_summaries_summary_abstractive   \n",
       "..     ...    ...                                                ...   \n",
       "102    101     25  101_coherence_discourse_discourse coherence_co...   \n",
       "103    102     25                     102_pos_taggers_tagging_tagger   \n",
       "104    103     24                 103_drug_social_social media_media   \n",
       "105    104     21            104_gender_translation_bias_gender bias   \n",
       "106    105     20                        105_job_resume_skills_skill   \n",
       "\n",
       "                                        Representation  \\\n",
       "0    [language, models, model, data, based, tasks, ...   \n",
       "1    [dialogue, dialog, response, responses, intent...   \n",
       "2    [speech, asr, speech recognition, recognition,...   \n",
       "3    [tuning, tasks, prompt, models, language, lang...   \n",
       "4    [summarization, summaries, summary, abstractiv...   \n",
       "..                                                 ...   \n",
       "102  [coherence, discourse, discourse coherence, co...   \n",
       "103  [pos, taggers, tagging, tagger, pos tagging, t...   \n",
       "104  [drug, social, social media, media, health, ad...   \n",
       "105  [gender, translation, bias, gender bias, mt, m...   \n",
       "106  [job, resume, skills, skill, soft, resumes, ti...   \n",
       "\n",
       "                                                   POS  \\\n",
       "0    [language, models, model, data, tasks, text, t...   \n",
       "1    [dialogue, dialog, response, responses, intent...   \n",
       "2    [speech, recognition, acoustic, automatic spee...   \n",
       "3    [tuning, tasks, prompt, models, language, trai...   \n",
       "4    [summarization, summaries, summary, abstractiv...   \n",
       "..                                                 ...   \n",
       "102  [coherence, discourse, text, paragraph, models...   \n",
       "103  [taggers, tagging, tagger, tags, tag, speech, ...   \n",
       "104  [drug, social, social media, media, health, ad...   \n",
       "105  [gender, translation, bias, grammatical gender...   \n",
       "106  [job, resume, skills, skill, soft, resumes, ti...   \n",
       "\n",
       "                                       KeyBERTInspired  \\\n",
       "0    [language processing, language models, embeddi...   \n",
       "1    [task oriented dialogue, dialogue systems, ori...   \n",
       "2    [speech recognition asr, automatic speech, spe...   \n",
       "3    [pre trained language, trained language models...   \n",
       "4    [summarization models, summarization model, ab...   \n",
       "..                                                 ...   \n",
       "102  [discourse coherence, coherent text, coherence...   \n",
       "103  [speech tagging, speech pos tagging, tagged co...   \n",
       "104  [topic modeling, social media data, corpus, me...   \n",
       "105  [machine translation, neural machine translati...   \n",
       "106  [resumes, job, information extraction, resume,...   \n",
       "\n",
       "                                                   MMR  \\\n",
       "0    [language, models, model, data, based, tasks, ...   \n",
       "1    [dialogue, dialog, response, responses, intent...   \n",
       "2    [speech, asr, speech recognition, recognition,...   \n",
       "3    [tuning, tasks, prompt, models, language, lang...   \n",
       "4    [summarization, summaries, summary, abstractiv...   \n",
       "..                                                 ...   \n",
       "102  [coherence, discourse, discourse coherence, co...   \n",
       "103  [pos, taggers, tagging, tagger, pos tagging, t...   \n",
       "104  [drug, social, social media, media, health, ad...   \n",
       "105  [gender, translation, bias, gender bias, mt, m...   \n",
       "106  [job, resume, skills, skill, soft, resumes, ti...   \n",
       "\n",
       "                                         KeyBERT + MMR  \\\n",
       "0    [language processing, language models, embeddi...   \n",
       "1    [task oriented dialogue, dialogue systems, ori...   \n",
       "2    [speech recognition asr, automatic speech, spe...   \n",
       "3    [pre trained language, trained language models...   \n",
       "4    [summarization models, summarization model, ab...   \n",
       "..                                                 ...   \n",
       "102  [discourse coherence, coherent text, coherence...   \n",
       "103  [speech tagging, speech pos tagging, tagged co...   \n",
       "104  [topic modeling, social media data, corpus, me...   \n",
       "105  [machine translation, neural machine translati...   \n",
       "106  [resumes, job, information extraction, resume,...   \n",
       "\n",
       "                                          OpenAI_Label  \\\n",
       "0    [Advancements in Multilingual Language Models ...   \n",
       "1    [Challenges and Approaches in Developing Task-...   \n",
       "2    [Automatic Speech Recognition Systems for Mult...   \n",
       "3    [Parameter-efficient fine-tuning of language m...   \n",
       "4    [Challenges in Abstractive Text Summarization ...   \n",
       "..                                                 ...   \n",
       "102  [Coherence modeling in written and spoken disc...   \n",
       "103  [Challenges and Approaches in POS Tagging for ...   \n",
       "104  [Social Media and Drug Safety in Pharmacovigil...   \n",
       "105  [Gender Bias in Machine Translation and Gender...   \n",
       "106     [Machine Learning for Job and Resume Matching]   \n",
       "\n",
       "                                        OpenAI_Summary  Representative_Docs  \n",
       "0    [Pre-trained Language Models and Embeddings fo...                  NaN  \n",
       "1    [Task-oriented dialogue systems and their comp...                  NaN  \n",
       "2    [Speech recognition and transcription, includi...                  NaN  \n",
       "3    [Pre-trained language models and parameter-eff...                  NaN  \n",
       "4    [Text Summarization Models and Systems\\n\\nThe ...                  NaN  \n",
       "..                                                 ...                  ...  \n",
       "102  [Modeling and Understanding Discourse Coherenc...                  NaN  \n",
       "103  [This topic is focused on the importance of pa...                  NaN  \n",
       "104  [This topic revolves around the use of social ...                  NaN  \n",
       "105  [This topic discusses gender-related issues in...                  NaN  \n",
       "106  [Topic: Job Information Extraction and Classif...                  NaN  \n",
       "\n",
       "[107 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "topic_model = BERTopic.load(\"MaartenGr/BERTopic_ArXiv\")\n",
    "\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cuml\n",
      "  Downloading cuml-0.6.1.post1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: cuml\n",
      "  Building wheel for cuml (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[45 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m /home/aryavachin/.pyenv/versions/lewagon/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please avoid running ``setup.py`` directly.\n",
      "  \u001b[31m   \u001b[0m         Instead, use pypa/build, pypa/installer or other\n",
      "  \u001b[31m   \u001b[0m         standards-based tools.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   self.initialize_options()\n",
      "  \u001b[31m   \u001b[0m installing to build/bdist.linux-x86_64/wheel\n",
      "  \u001b[31m   \u001b[0m running install\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-ey0gwn20/cuml_29da357f38e14122a28b51aa4d08973c/setup.py\", line 18, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(name=pkg,\n",
      "  \u001b[31m   \u001b[0m   File \"/home/aryavachin/.pyenv/versions/lewagon/lib/python3.10/site-packages/setuptools/__init__.py\", line 104, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/aryavachin/.pyenv/versions/lewagon/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/aryavachin/.pyenv/versions/lewagon/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/aryavachin/.pyenv/versions/lewagon/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/aryavachin/.pyenv/versions/lewagon/lib/python3.10/site-packages/setuptools/dist.py\", line 967, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/aryavachin/.pyenv/versions/lewagon/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/aryavachin/.pyenv/versions/lewagon/lib/python3.10/site-packages/wheel/bdist_wheel.py\", line 399, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(\"install\")\n",
      "  \u001b[31m   \u001b[0m   File \"/home/aryavachin/.pyenv/versions/lewagon/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/aryavachin/.pyenv/versions/lewagon/lib/python3.10/site-packages/setuptools/dist.py\", line 967, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/aryavachin/.pyenv/versions/lewagon/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-ey0gwn20/cuml_29da357f38e14122a28b51aa4d08973c/setup.py\", line 15, in run\n",
      "  \u001b[31m   \u001b[0m     raise Exception(long_description)\n",
      "  \u001b[31m   \u001b[0m Exception: Please install cuml via the rapidsai conda channel. See https://rapids.ai/start.html for instructions.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for cuml\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for cuml\n",
      "Failed to build cuml\n",
      "\u001b[31mERROR: Could not build wheels for cuml, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install cuml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryavachin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/astroid/node_classes.py:94: DeprecationWarning: The 'astroid.node_classes' module is deprecated and will be replaced by 'astroid.nodes' in astroid 3.0.0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cuml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanifold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UMAP\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HDBSCAN\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbertopic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BERTopic\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cuml'"
     ]
    }
   ],
   "source": [
    "from cuml.manifold import UMAP\n",
    "from cuml.cluster import HDBSCAN\n",
    "from bertopic.representation import PartOfSpeech, KeyBERTInspired, MaximalMarginalRelevance, OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare sub-models\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "umap_model = UMAP(n_components=5, n_neighbors=50, random_state=42, metric=\"cosine\", verbose=True)\n",
    "hdbscan_model = HDBSCAN(min_samples=20, gen_min_span_tree=True, prediction_data=False, min_cluster_size=20, verbose=True)\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\", ngram_range=(1, 3), min_df=5)\n",
    "\n",
    "# Summarization with ChatGPT\n",
    "summarization_prompt = \"\"\"\n",
    "I have a topic that is described by the following keywords: [KEYWORDS]\n",
    "In this topic, the following documents are a small but representative subset of all documents in the topic:\n",
    "[DOCUMENTS]\n",
    "\n",
    "Based on the information above, please give a description of this topic in the following format:\n",
    "topic: <description>\n",
    "\"\"\"\n",
    "summarization_model = OpenAI(model=\"gpt-3.5-turbo\", chat=True, prompt=summarization_prompt, nr_docs=5, exponential_backoff=True, diversity=0.1)\n",
    "\n",
    "# Representation models\n",
    "representation_models = {\n",
    "    \"POS\": PartOfSpeech(\"en_core_web_lg\"),\n",
    "    \"KeyBERTInspired\": KeyBERTInspired(),\n",
    "    \"MMR\": MaximalMarginalRelevance(diversity=0.3),\n",
    "    \"KeyBERT + MMR\": [KeyBERTInspired(), MaximalMarginalRelevance(diversity=0.3)],\n",
    "    \"OpenAI_Label\": OpenAI(model=\"gpt-3.5-turbo\", exponential_backoff=True, chat=True, diversity=0.1),\n",
    "    \"OpenAI_Summary\": [KeyBERTInspired(), summarization_model],\n",
    "}\n",
    "\n",
    "# Fit BERTopic\n",
    "topic_model= BERTopic(\n",
    "        embedding_model=embedding_model,\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        representation_model=representation_models,\n",
    "        verbose=True\n",
    ").fit(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create v2\n",
    "# phrase_to_exclude = \"No, currently I don't identify as having a chronic pain condition.\"\n",
    "\n",
    "# # Create a mask for rows where 'personalhistory' column's value is exactly the phrase_to_exclude\n",
    "# mask = df_transformed['PersonalHistory'] != phrase_to_exclude\n",
    "\n",
    "# # Apply the mask to filter out the rows\n",
    "# df_transformed_filtered = df_transformed[mask]\n",
    "\n",
    "# # Display the information and the first 3 rows of the filtered DataFrame\n",
    "# print(df_transformed_filtered.info())\n",
    "# df_transformed_filtered.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply the transformations for LDA for v2\n",
    "# df_transformed_filtered = df_transformed_filtered.drop(columns=to_drop, errors='ignore')\n",
    "\n",
    "# df_split_2, lda_details_2 = splitting_into_topics(df_transformed_filtered,topics_per_column,textual_columns)\n",
    "# preprocessor_2 = build_preprocessor(textual_columns, categorical_columns, datetime_columns)\n",
    "# df_LDA_2 = preprocessor_2.fit_transform(df_split_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_columns_2 = preprocessor_2.get_feature_names_out()\n",
    "# df_final_2 = pd.DataFrame(df_LDA_2, columns=transformed_columns_2)\n",
    "# df_final_2 = df_final_2.apply(pd.to_numeric)\n",
    "\n",
    "# print(df_final_2.info())\n",
    "# df_final_2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_ph =lda_details['PersonalHistory']['lda']\n",
    "x_ph = lda_details['PersonalHistory']['X']\n",
    "vect_ph = lda_details['PersonalHistory']['vect']\n",
    "\n",
    "lda_visual(lda_ph, x_ph, vect_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_m =lda_details['Motivation']['lda']\n",
    "x_m = lda_details['Motivation']['X']\n",
    "vect_m = lda_details['Motivation']['vect']\n",
    "\n",
    "lda_visual(lda_m, x_m, vect_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_columns = preprocessor.get_feature_names_out()\n",
    "df_final = pd.DataFrame(df_LDA, columns=transformed_columns)\n",
    "df_final = df_final.apply(pd.to_numeric)\n",
    "\n",
    "print(df_final.info())\n",
    "df_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrolation stuff\n",
    "# df_new = remove_low_variance_features(df_final)\n",
    "# df_new_2 = remove_high_correlation_features(df_new)\n",
    "\n",
    "# corr_df = df_final.corr()\n",
    "# for idx, col in corr_df.iterrows():\n",
    "#     if abs(col) >= 0.25 :\n",
    "#         print(col)\n",
    "\n",
    "# corr_plot(df_final)\n",
    "\n",
    "# # PCA transform\n",
    "# df_proj, labels = transform_data(df_final, 4, 2)\n",
    "\n",
    "# print(df_proj.info())\n",
    "# df_proj.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_clusters(df_proj, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1a='remainder__PersonalHistory_Topic0'\n",
    "col2a='remainder__Motivation_Topic0'\n",
    "col1b='remainder__PersonalHistory_Topic1'\n",
    "col2b='remainder__Motivation_Topic1'\n",
    "col1c='remainder__PersonalHistory_Topic2'\n",
    "col2c='remainder__Motivation_Topic2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3d = df_final[[col1a,col2a,col2b]]\n",
    "labelling_3d = fit_kmeans_and_label(df_3d,4)\n",
    "label_dataframe(df_3d, labelling_3d)\n",
    "print(df_3d.info())\n",
    "df_3d.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([df_3d,df_final[['PersonalHistory']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters_3d(df_3d,labelling_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2d = df_final[[col1b,col2a]]\n",
    "# labelling = fit_kmeans_and_label(df_2d,4)\n",
    "# label_dataframe(df_2d, labelling)\n",
    "# print(df_2d.info())\n",
    "# df_2d.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_clusters_2d(df_2d,labelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_pairs = [\n",
    "    (col1a, col2a),\n",
    "    (col1a, col2b),\n",
    "    # (col1a, col2c),\n",
    "    (col1b, col2a),\n",
    "    (col1b, col2b),\n",
    "    # (col1b, col2c),\n",
    "    # (col1c, col2a),\n",
    "    # (col1c, col2b),\n",
    "    # (col1c, col2c),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lda(df_final,column_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_lda(df_final_2,column_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avatars = {}\n",
    "df_labelled = pd.concat([df_transformed,pd.Series(labelling)],axis=1).rename(columns={0:\"label\"})\n",
    "\n",
    "for numero_cluster in np.unique(labelling):\n",
    "    avatars[numero_cluster] = df_labelled[df_labelled.label == numero_cluster]\n",
    "\n",
    "for key,value in avatars.items():\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Here are some people fitting into Avatar {key}\")\n",
    "    print(\"-\"*50)\n",
    "    display(value.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Location'] = df['Location'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_location_category(location):\n",
    "#     if 'manchester' in location:\n",
    "#         return 'Manchester'\n",
    "#     elif 'liverpool' in location or 'merseyside' in location:\n",
    "#         return 'Liverpool'\n",
    "#     elif 'london' in location:\n",
    "#         return 'London'\n",
    "#     elif 'united states' in location or 'utah' in location:\n",
    "#         return 'United States'\n",
    "#     elif 'denmark' in location or 'croatia' in location or 'poland' in location or 'norway' in location or 'germany' in location or 'barcelona' in location:\n",
    "#         return 'EUR'\n",
    "#     elif 'australia' in location:\n",
    "#         return 'Australia'\n",
    "#     elif 'india' in location or 'maldives' in location:\n",
    "#         return 'SAsia'\n",
    "#     elif 'uruguay' in location:\n",
    "#         return 'SAmerica'\n",
    "#     elif 'united kingdom' in location:\n",
    "#         return 'UK'\n",
    "#     else:\n",
    "#         return 'England'\n",
    "\n",
    "# df_drop['Location_Category'] = df_drop['Location'].apply(get_location_category)\n",
    "# df_drop.Location_Category.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X, y=None):\n",
    "#         cleaned_data = X.applymap(self.clean_text)\n",
    "#         return cleaned_data\n",
    "\n",
    "#     def clean_text(self, text):\n",
    "#         text = str(text)\n",
    "#         for punctuation in string.punctuation:\n",
    "#             text = text.replace(punctuation, ' ')  # Remove Punctuation\n",
    "#         lowercased = text.lower()  # Lower Case\n",
    "#         tokenized = word_tokenize(lowercased)  # Tokenize\n",
    "#         words_only = [word for word in tokenized if word.isalpha()]  # Remove numbers\n",
    "\n",
    "#         stop_words = set(stopwords.words('english'))\n",
    "#         stop_words.update(['yes','none','nan'])\n",
    "\n",
    "#         without_stopwords = [word for word in words_only if not word in stop_words]  # Remove Stop Words\n",
    "#         lemma = WordNetLemmatizer()  # Initiate Lemmatizer\n",
    "#         lemmatized = [lemma.lemmatize(word) for word in without_stopwords]  # Lemmatize\n",
    "#         cleaned = ' '.join(lemmatized)  # Join back to a string\n",
    "#         return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA()\n",
    "# pca.fit(df_num)\n",
    "# threhsold_pca = 4\n",
    "# with plt.style.context('seaborn-deep'):\n",
    "#     # figsize\n",
    "#     plt.figure(figsize=(10,6))\n",
    "#     # getting axes\n",
    "#     ax = plt.gca()\n",
    "#     # plotting\n",
    "#     explained_variance_ratio_cumulated = np.cumsum(pca.explained_variance_ratio_)\n",
    "#     x_axis_ticks = np.arange(1,explained_variance_ratio_cumulated.shape[0]+1)\n",
    "#     ax.plot(x_axis_ticks,explained_variance_ratio_cumulated,label=\"cumulated variance ratio\",color=\"purple\",linestyle=\":\",marker=\"D\",markersize=10)\n",
    "#     # customizing\n",
    "#     ax.set_xlabel('Number of Principal Components')\n",
    "#     ax.set_ylabel('% cumulated explained variance')\n",
    "#     ax.legend(loc=\"upper left\")\n",
    "#     ax.set_title('The Elbow Method')\n",
    "#     ax.set_xticks(x_axis_ticks)\n",
    "#     ax.scatter(threhsold_pca,explained_variance_ratio_cumulated[threhsold_pca-1],c='blue',s=400)\n",
    "#     ax.grid(axis=\"x\",linewidth=0.5)\n",
    "#     ax.grid(axis=\"y\",linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_scaled = px.scatter_3d(df_proj, x = 0, y = 1, z = 2, opacity=0.7, width=500, height=500)\n",
    "# fig_scaled.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_clusters_to_try = np.arange(1,10+1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wcss = []\n",
    "# for K in nb_clusters_to_try:\n",
    "#     kmeans = KMeans(n_clusters = K)\n",
    "#     kmeans.fit(df_proj)\n",
    "#     wcss.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elbow_highlight = 3\n",
    "# with plt.style.context('seaborn-deep'):\n",
    "#     # figsize\n",
    "#     plt.figure(figsize=(20,10))\n",
    "#     # getting axes\n",
    "#     ax = plt.gca()\n",
    "#     # plotting\n",
    "#     ax.plot(nb_clusters_to_try, wcss,color=\"blue\",linestyle=\":\",marker=\"D\",label=\"Inertia\")\n",
    "#     # customizing\n",
    "#     ax.legend(loc=\"upper right\")\n",
    "#     ax.set_title('The Elbow Method')\n",
    "#     ax.set_xticks(nb_clusters_to_try)\n",
    "#     ax.set_xlabel('Number of clusters')\n",
    "#     ax.set_ylabel('Within-Cluster Sums of Squares')\n",
    "#     ax.scatter(elbow_highlight,wcss[elbow_highlight-1],c='red',s=400)\n",
    "\n",
    "#     ax.grid(axis=\"y\",linewidth=0.5)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
